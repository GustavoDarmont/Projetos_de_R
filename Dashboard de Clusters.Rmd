---
title: "Dashboard de Clusters de Risco e Retorno (B3)"
author: "Gustavo Darmont de Faria Lima"
date: "2025-12-01"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    theme: flatly
runtime: shiny
---

```{r setup}
# --- 1. PACOTES ---
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  shiny, 
  tidyverse, 
  tidyquant, 
  yfR, 
  cluster, 
  ggrepel, 
  plotly, 
  DT, 
  rbcb,
  crosstalk,
  patchwork,
  heatmaply
)

# --- 2. DADOS E PARÂMETROS ---

# Período de análise padrão de 5 anos (será substituído pelos inputs do usuário)
data_fim_padrao <- Sys.Date()
data_inicio_padrao <- data_fim_padrao - lubridate::years(5)

# Lista de Tickers (27 empresas de 7 setores distintos e 2 benchmarks)
tickers_acao <- c(
  "VALE3.SA", "CMIN3.SA", "BRAP4.SA", # Mineração
  "SBSP3.SA", "SAPR11.SA", "CSMG3.SA", "ORVR3.SA", # Água e Saneamento
  "RDOR3.SA", "FLRY3.SA", # Saúde
  "SUZB3.SA", "KLBN11.SA", # Papel e Celulose
  "ITUB4.SA", "BBDC4.SA", "BPAC11.SA", "ITSA4.SA", "BBAS3.SA", "BBDC3.SA", # Financeiro
  "PETR4.SA", "PETR3.SA", "PRIO3.SA", "VBBR3.SA", "UGPA3.SA", # Petróleo
  "ELET3.SA", "EQTL3.SA", "ENEV3.SA", "CPLE6.SA", "CMIG4.SA" # Energia
)
tickers_bench <- c("^BVSP", "^GSPC")
todos_tickers <- c(tickers_acao, tickers_bench)

# Dataframe de Setores
setores_df <- tibble::tribble(
  ~ticker,    ~Setor,
  "VALE3.SA", "Mineração",
  "CMIN3.SA", "Mineração",
  "BRAP4.SA", "Mineração",
  "SBSP3.SA", "Água e Saneamento",
  "SAPR11.SA", "Água e Saneamento",
  "CSMG3.SA", "Água e Saneamento",
  "ORVR3.SA", "Água e Saneamento",
  "RDOR3.SA", "Serv.Méd.Hospit.,Análises e Diag.",
  "FLRY3.SA", "Serv.Méd.Hospit.,Análises e Diag.",
  "SUZB3.SA", "Madeira e Papel",
  "KLBN11.SA", "Madeira e Papel", 
  "ITUB4.SA", "Intermediários Financeiros",
  "BBDC4.SA", "Intermediários Financeiros",
  "BPAC11.SA", "Intermediários Financeiros",
  "ITSA4.SA", "Intermediários Financeiros",
  "BBAS3.SA", "Intermediários Financeiros",
  "BBDC3.SA", "Intermediários Financeiros",
  "PETR4.SA", "Petróleo, Gás e Biocombustíveis",
  "PETR3.SA", "Petróleo, Gás e Biocombustíveis",
  "PRIO3.SA", "Petróleo, Gás e Biocombustíveis",
  "VBBR3.SA", "Petróleo, Gás e Biocombustíveis",
  "UGPA3.SA", "Petróleo, Gás e Biocombustíveis",
  "ELET3.SA", "Energia Elétrica",
  "EQTL3.SA", "Energia Elétrica",
  "ENEV3.SA", "Energia Elétrica",
  "CPLE6.SA", "Energia Elétrica",
  "CMIG4.SA", "Energia Elétrica"
)

# --- 3. DOWNLOAD E TRATAMENTO ---

# Baixa os dados de preços ajustados (usando período padrão, será filtrado depois)
dados_precos <- yf_get(
  tickers = todos_tickers,
  first_date = data_inicio_padrao,
  last_date = data_fim_padrao
)

# Selic do BCB
dados_selic_raw <- rbcb::get_series(432, start_date = data_inicio_padrao, end_date = data_fim_padrao)
dados_selic <- dados_selic_raw %>%
  rename(Data = date, Selic_Anual = `432`) %>%
  mutate(Risk_Free_Diario = (1 + Selic_Anual/100)^(1/252) - 1)

# Cálculo de Retornos
retornos_diarios <- dados_precos %>%
  select(ref_date, ticker, price_adjusted) %>%
  group_by(ticker) %>%
  arrange(ref_date) %>%
  mutate(retorno_diario = c(NA, diff(log(price_adjusted)))) %>%
  ungroup() %>%
  rename(Data = ref_date) %>%
  drop_na()

# Join Mestre
dados_mestre <- left_join(retornos_diarios, dados_selic %>% select(Data, Risk_Free_Diario), by = "Data") %>%
  drop_na()

# --- 4. FEATURES E K-MEANS ---

features_cluster <- dados_mestre %>%
  filter(!ticker %in% tickers_bench) %>%
  group_by(ticker) %>%
  summarise(
    retorno_medio_diario = mean(retorno_diario),
    volatilidade_diaria = sd(retorno_diario),
    Risk_Free_Medio = mean(Risk_Free_Diario)
  ) %>%
  mutate(
    RetornoAnual = retorno_medio_diario * 252,
    VolAnual = volatilidade_diaria * sqrt(252),
    Risk_Free_Anual = (1 + Risk_Free_Medio)^252 - 1,
    Sharpe = (RetornoAnual - Risk_Free_Anual) / VolAnual
  ) %>%
  left_join(setores_df, by = "ticker") %>%
  drop_na()

# Metodologia (Cálculo do Cotovelo para a Aba Metodologia)
dados_cluster_matrix <- features_cluster %>% select(RetornoAnual, VolAnual, Sharpe) %>% scale()
metrics_df <- map_dfr(2:10, function(k) {
  set.seed(123)
  model <- kmeans(dados_cluster_matrix, centers = k, nstart = 25)
  sil <- silhouette(model$cluster, dist(dados_cluster_matrix))
  tibble(k = k, inercia = model$tot.withinss, silhueta = mean(sil[, 3]))
})

# Aplicação Final do K-Means (K=3)
set.seed(123)
kmeans_final <- kmeans(dados_cluster_matrix, centers = 3, nstart = 25)
features_com_cluster <- features_cluster %>%
  mutate(Cluster = as.factor(kmeans_final$cluster))

# --- 5. CROSSTALK (Shared Data) ---
dados_shared <- SharedData$new(features_com_cluster, key = ~ticker, group = "analise")
```


```{r}
# --- LÓGICA REATIVA (SHINY) ---

# 1. Filtra dados pelo período e tickers excluídos
dados_filtrados <- reactive({
  req(input$data_inicio, input$data_fim)
  
  # Tickers a manter (removendo os excluídos)
  tickers_validos <- setdiff(tickers_acao, input$excluir_tickers)
  
  # Filtra dados mestre por período e tickers
  dados_filtrados_tmp <- dados_mestre %>%
    filter(Data >= input$data_inicio, 
           Data <= input$data_fim,
           ticker %in% c(tickers_validos, tickers_bench))
  
  return(dados_filtrados_tmp)
})

# 2. Calcula features com dados filtrados (só ações, sem benchmarks)
features_filtradas <- reactive({
  dados_filtrados_tmp <- dados_filtrados()
  
  feat <- dados_filtrados_tmp %>%
    filter(!ticker %in% tickers_bench) %>%
    group_by(ticker) %>%
    summarise(
      retorno_medio_diario = mean(retorno_diario),
      volatilidade_diaria = sd(retorno_diario),
      Risk_Free_Medio = mean(Risk_Free_Diario)
    ) %>%
    mutate(
      RetornoAnual = retorno_medio_diario * 252,
      VolAnual = volatilidade_diaria * sqrt(252),
      Risk_Free_Anual = (1 + Risk_Free_Medio)^252 - 1,
      Sharpe = (RetornoAnual - Risk_Free_Anual) / VolAnual
    ) %>%
    left_join(setores_df, by = "ticker") %>%
    drop_na()
  
  return(feat)
})

# 3. Calcula métricas dos benchmarks
benchmarks_metricas <- reactive({
  dados_filtrados_tmp <- dados_filtrados()
  
  bench <- dados_filtrados_tmp %>%
    filter(ticker %in% tickers_bench) %>%
    group_by(ticker) %>%
    summarise(
      retorno_medio_diario = mean(retorno_diario),
      volatilidade_diaria = sd(retorno_diario),
      Risk_Free_Medio = mean(Risk_Free_Diario)
    ) %>%
    mutate(
      RetornoAnual = retorno_medio_diario * 252,
      VolAnual = volatilidade_diaria * sqrt(252),
      Risk_Free_Anual = (1 + Risk_Free_Medio)^252 - 1,
      Sharpe = (RetornoAnual - Risk_Free_Anual) / VolAnual,
      Cluster = "Benchmark",
      Setor = "Benchmark"
    )
  
  return(bench)
})

# 4. Recalcula os Clusters baseado no Slider (input$k_clusters)
dados_reativos <- reactive({
  req(input$k_clusters)
  feat <- features_filtradas()
  
  if(nrow(feat) < input$k_clusters) {
    return(feat %>% mutate(Cluster = as.factor(1)))
  }
  
  # Matriz para clustering
  dados_matrix <- feat %>% 
    select(RetornoAnual, VolAnual, Sharpe) %>% 
    scale()
  
  set.seed(123)
  kmeans_dinamico <- kmeans(dados_matrix, centers = input$k_clusters, nstart = 25)
  
  # Cria o dataframe atualizado com o novo Cluster
  df_final <- feat %>%
    mutate(Cluster = as.factor(kmeans_dinamico$cluster))
  
  # Aplica filtro de setor se selecionado
  if(!is.null(input$filtro_setor) && length(input$filtro_setor) > 0 && input$filtro_setor[1] != "") {
    df_final <- df_final %>%
      filter(Setor %in% input$filtro_setor)
  }
  
  return(df_final)
})
```

Sidebar {.sidebar}
=====================================

```{r Parametros}
# --- FILTROS E CONTROLES ---

# 1. Filtro de Período
dateInput("data_inicio", "Data Início:", 
          value = data_inicio_padrao, 
          min = data_inicio_padrao - lubridate::years(5),
          max = Sys.Date())

dateInput("data_fim", "Data Fim:", 
          value = data_fim_padrao, 
          min = data_inicio_padrao,
          max = Sys.Date())

HTML("<hr>")

# 2. Filtro de Tickers (Exclusão)
selectInput("excluir_tickers", "Excluir Tickers da Análise:", 
            choices = tickers_acao, 
            selected = NULL,
            multiple = TRUE)

HTML("<hr>")

# 3. Slider do K (Controla o K-Means)
sliderInput("k_clusters", "Número de Clusters (k):", 
            min = 2, max = 10, value = 3, step = 1)

HTML("<hr>")

# 4. Filtro de Setor
renderUI({
  setores_disponiveis <- features_filtradas() %>% 
    pull(Setor) %>% 
    unique() %>% 
    sort()
  
  selectInput("filtro_setor", 
              "Filtrar Setor:", 
              choices = c("Todos" = "", setores_disponiveis),
              selected = "",
              multiple = TRUE)
})

# Informações Macro
selic_hoje <- last(dados_selic$Selic_Anual)
```

Introdução {.tabset}
=====================================

### Apresentação: {data-height=110}
Este projeto busca, a partir da análise de 27 ações do mercado brasileiro, investigar se empresas de um mesmo setor da economia tendem a apresentar relações risco-retorno semelhantes. A metodologia consiste em extrair 5 anos de dados de preços (Yahoo Finance) para calcular alguns indicadores de cada ativo (Retorno, Volatilidade e Índice de Sharpe). Em seguida, o algoritmo de aprendizado não supervisionado K-Means é aplicado para agrupar os ativos, e os clusters resultantes são visualmente comparados com a classificação setorial oficial da B3. Por fim, adicionam-se os benchmarks índice Ibovespa, S&P500 e a taxa livre de risco da economia brasileira para compará-los com os clusters observados e buscar setores com índice de sharpe mais positivo. 

Abaixo, apresentam-se os gráficos para teste e descoberta do número ótimo de clusters. Selecione o k (número de clusters) que representa o ponto de maior score de silhueta e um "cotovelo" siginifcativo.

### Metodologia de Clusterização {data-height=340}

```{r Metodologia de Clusterizacao}
# ABA 1: Gráficos de suporte (Cotovelo e Silhueta) - Atualizado com dados filtrados
renderPlot({
  feat <- features_filtradas()
  
  if(nrow(feat) < 3) {
    plot.new()
    text(0.5, 0.5, "Dados insuficientes para análise", cex = 1.5)
    return()
  }
  
  # Recalcula métricas com dados filtrados
  dados_matrix <- feat %>% select(RetornoAnual, VolAnual, Sharpe) %>% scale()
  
  metrics_df_dinamico <- map_dfr(2:min(10, nrow(feat)-1), function(k) {
    set.seed(123)
    model <- kmeans(dados_matrix, centers = k, nstart = 25)
    sil <- silhouette(model$cluster, dist(dados_matrix))
    tibble(k = k, inercia = model$tot.withinss, silhueta = mean(sil[, 3]))
  })
  
  p1 <- ggplot(metrics_df_dinamico, aes(x = k, y = inercia)) +
    geom_line(color = "blue") + geom_point(size = 3, color = "blue") +
    geom_vline(xintercept = input$k_clusters, linetype = "dashed", color = "darkgreen", size = 1) +
    labs(title = "Método do Cotovelo", y = "Inércia", x = "Número de Clusters (k)") + 
    theme_minimal()

  p2 <- ggplot(metrics_df_dinamico, aes(x = k, y = silhueta)) +
    geom_line(color = "red") + geom_point(size = 3, color = "red") +
    geom_vline(xintercept = input$k_clusters, linetype = "dashed", color = "darkgreen", size = 1) +
    labs(title = "Silhueta Média", y = "Score", x = "Número de Clusters (k)") + 
    theme_minimal()

  p1 + p2
})
```

### {data-height=20}
Após a escolha do número de clusters ótimo para o conjunto de ativos selecionado, vá para aba seguinte onde poderá realizar a análise do projeto própriamente dita.


Análise de Clusters {.tabset}
=====================================

### Análise de Clusters {data-height=600}

```{r Graficos Clusters}
# GRÁFICOS LADO A LADO
splitLayout(cellWidths = c("50%", "50%"),

  # Esquerda: Dispersão com Benchmarks
  renderPlotly({
    df_acoes <- dados_reativos()
    df_bench <- benchmarks_metricas()
    
    # Customizada: Cluster para legenda (Cluster X), Benchmark separado
    df_acoes <- df_acoes %>%
      mutate(
        Cluster_leg = paste0("Cluster ", Cluster),
        Tipo_leg = ifelse(ticker %in% tickers_bench, "Benchmark", Cluster_leg)
      )
    df_bench <- df_bench %>% mutate(Tipo_leg = "Benchmark")

    df_completo <- bind_rows(
      df_acoes %>% mutate(legenda = Tipo_leg),
      df_bench %>% mutate(legenda = Tipo_leg)
    )

    p_scatter <- ggplot(df_completo, aes(x = VolAnual, y = RetornoAnual, 
                                         color = legenda, label = ticker)) +
      geom_point(aes(shape = ifelse(ticker %in% tickers_bench, "Benchmark", "Ação")), 
                 size = 3, alpha = 0.8) +
      geom_text_repel(aes(label = ticker), size = 3, max.overlaps = 15) +
      scale_y_continuous(labels = scales::percent) +
      scale_x_continuous(labels = scales::percent) +
      scale_color_brewer(palette = "Set1") +
      scale_shape_manual(values = c("Ação" = 16, "Benchmark" = 17)) +
      labs(title = "Risco vs Retorno (com Benchmarks)", 
           x = "Volatilidade", y = "Retorno", color = "Cluster", shape = "Tipo") +
      guides(shape = "none") +
      theme_minimal() + theme(legend.position = "bottom")

    ggplotly(p_scatter, tooltip = c("label", "x", "y"), height = 400) %>%
      layout(
        height = 400,
        margin = list(b = 40, t = 50, l = 50, r = 50),
        legend = list(orientation = "h", x = 0.5, xanchor = "center", y = -0.3, yanchor = "top")
      )
  }),

  # Direita: Setores com Elipses e Benchmarks
  renderPlotly({
    df_acoes <- dados_reativos()
    df_bench <- benchmarks_metricas()
    
    df_acoes <- df_acoes %>% 
      mutate(
        Setor_leg = Setor,
        Setor_leg = ifelse(ticker %in% tickers_bench, "Benchmark", Setor_leg)
      )
    df_bench <- df_bench %>% mutate(Setor_leg = "Benchmark")

    df_completo <- bind_rows(
      df_acoes %>% mutate(legenda = Setor_leg),
      df_bench %>% mutate(legenda = Setor_leg)
    )

    p_setor <- ggplot(df_completo, aes(x = VolAnual, y = RetornoAnual, label = ticker)) +
      stat_ellipse(data = df_acoes, aes(group = Cluster), type = 't', level = 0.95, 
                   color = "gray", linetype = "dashed") +
      geom_point(aes(color = legenda, shape = ifelse(ticker %in% tickers_bench, "Benchmark", "Ação")), 
                 size = 2.5, alpha = 0.8) +
      geom_text_repel(aes(label = ticker), size = 3, max.overlaps = 15) +
      scale_y_continuous(labels = scales::percent) +
      scale_x_continuous(labels = scales::percent) +
      scale_shape_manual(values = c("Ação" = 16, "Benchmark" = 17)) +
      labs(title = "Clusters vs Setores (com Benchmarks)", 
           x = "Volatilidade", y = "Retorno", color = "Setor", shape = NULL) +
      guides(shape = "none") +
      theme_minimal() + theme(legend.position = "bottom")

    ggplotly(p_setor, tooltip = c("label", "x", "y"), height = 400) %>%
      layout(
        height = 400,
        margin = list(b = 80, t = 50, l = 10, r = 50),
        legend = list(orientation = "h", x = 0.5, xanchor = "center", y = -0.35, yanchor = "top")
      )
  })
)
```

### Tabela Detalhada {data-height=400}

```{r Tabela Clusters}
# TABELA DETALHADA
renderDT({
  datatable(dados_reativos(), 
            rownames = FALSE,
            extensions = 'Buttons',
            options = list(dom = 'Bfrtip', buttons = c('copy', 'csv'), pageLength = 15,
                           columnDefs = list(list(visible = FALSE, targets = c(1, 2, 3))))) %>%
    formatPercentage(c("RetornoAnual", "VolAnual"), 2) %>%
    formatRound("Sharpe", 2) %>%
    formatStyle('RetornoAnual', color = styleInterval(0, c('#D32F2F', '#388E3C')), fontWeight = 'bold') %>%
    formatStyle('Sharpe', color = styleInterval(0, c('#D32F2F', '#388E3C')), fontWeight = 'bold') %>%
    formatStyle('Cluster', backgroundColor = styleEqual(c(1, 2, 3), c('#fce4ec', '#e8f5e9', '#e3f2fd')))
})
```

Correlação {.tabset}
=====================================

### Correlação

```{r Correlacao}
# ABA 3: Heatmap com Benchmarks e Risk-Free
renderPlotly({
  df_atual <- dados_reativos()
  tickers_ativos <- c(df_atual$ticker, tickers_bench)
  
  # Filtra dados pelo período selecionado
  dados_filtrados_tmp <- dados_filtrados()
  
  # Pivot data to wide format for correlation calculation
  dados_matrix <- dados_filtrados_tmp %>%
    filter(ticker %in% tickers_ativos) %>%
    select(Data, ticker, retorno_diario) %>%
    pivot_wider(names_from = ticker, values_from = retorno_diario)
  
  # Adiciona coluna de Risk-Free
  dados_matrix <- dados_matrix %>%
    left_join(dados_selic %>% select(Data, Risk_Free_Diario), by = "Data") %>%
    rename(RiskFree = Risk_Free_Diario)
  
  # Remove coluna Data e calcula correlação
  dados_matrix_final <- dados_matrix %>% select(-Data)
  cormat <- cor(dados_matrix_final, use = "pairwise.complete.obs")
  
  heatmaply::heatmaply(
    cormat,
    main = "Matriz de Correlação (com Benchmarks e Risk-Free)",
    colors = viridis::viridis(200),
    limits = c(-1, 1),
    k_col = input$k_clusters, 
    k_row = input$k_clusters,
    label_names = c("Ativo X", "Ativo Y", "Correlação"),
    height = 800
  )
})
```

Documentação {.tabset}
=====================================

### Fontes de Dados:
Este projeto utiliza duas fontes de dados distintas para a análise, com o objetivo de combinar as informações referentes às empresas e índices de mercado com a taxa livre de risco da economia brasileira.

1. Preços das Ações e Índices de Bolsa: Yahoo Finance
Os dados históricos de preços de fechamento ajustados para as 27 ações e 2 índices de bolsas selecionados foram coletados diretamente da plataforma Yahoo Finance. A extração foi automatizada por meio da API disponibilizada pelo pacote yfR da linguagem R. Os dados correspondem ao período de 5 anos imediatamente anterior à data de execução do código, garantindo uma análise atualizada.

2. Histórico da Taxa Básica de Juros - Selic: API Banco Central
A série histórica da taxa selic foi extraída diretamente do banco de dados do Banco Central via API disponibilizada pela instituição.

### Análise dos Dados:

1. Gráficos de Clusterização: Estes gráficos devem ser interpretados em conjunto para avaliar a eficiência dos ativos e a coerência setorial:

Risco vs Retorno (Dispersão): Esse primeiro olhar objetiva identificar ativos eficientes. Os gráficos permitem, em uma primeira instância, identificar os ativos e clusters com melhor e pior relação risco-retorno. Os melhores ativos estão localizados no canto superior esquerdo do gráfico (alto retorno anualizado e baixa volatilidade). Pode-se Utilizar os triângulos (Benchmarks) como pontos de referência: ativos abaixo ou à direita dos benchmarks destruíram valor ajustado ao risco no período selecionado.

Clusters vs Setores (Elipses): O gráfico da direita tem por objetivo validar a hipótese setorial. Nele pode-se obsevar a distribuição das cores (Setores) em relação às linhas pontilhadas (Clusters). Se os pontos de uma mesma cor estiverem agrupados dentro de uma única elipse, há forte evidência de comportamento setorial. Se os pontos de uma cor estiverem espalhados por diversas elipses, indica que o fator "Setor" não é determinante para o risco-retorno desses ativos no período analisado.

Nota: Você pode clicar diretamente nos itens da legenda de cada gráfico para filtrar a análise.


2. Tabela Detalhada: Localizada logo abaixo dos gráficos de clusters, esta tabela serve para a inspeção granular e criação de rankings.

Ordenação: Clique nos cabeçalhos (ex: "Sharpe" ou "RetornoAnual") para ordenar os ativos e identificar com maior facilidade os "Top Performers" ou os piores desempenhos do período filtrado.

Identificação Visual: A formatação condicional (Verde/Vermelho) do Índice de Sharpe de cada ativo auxilia na segmentação direta de ativos geradores de valor daqueles que deram prejuízo relativo ou tiveram Sharpe negativo.


3. Heatmap: A Matriz de Correlação tem como objetivo principal auxiliar na escolha diversificada de ativos e na validação dos clusters:

Diversificação: Ativos que apresentem cruzamentos em tons claros/amarelos detém alta correlação positiva, pois tendem a performar de forma semelhante. Pares de ativos com cores escuras/roxas detém correlação baixa ou negativa, servindo como proteção mútua (hedge) a uma carteira.

Validação: O dendrograma (a árvore de agrupamento nas bordas do gráfico) organiza os ativos por similaridade estatística. Por ele pode-se verificar se os ativos que o algoritmo K-Means agrupou no mesmo cluster (na aba anterior) também aparecem próximos uns aos outros nesta árvore.

### Glossário de Variáveis:
Esta seção descreve os principais dataframes e variáveis criados e utilizados ao longo da análise para garantir a clareza e a reprodutibilidade do estudo.

Principais Dataframes:

- setores_df: Tabela de mapeamento criada manualmente que associa cada ticker de ação ao seu respectivo Setor econômico, conforme a classificação da B3.

- dados_precos: Dataframe contendo os dados históricos de preços ajustados de todos os ativos (ações e benchmarks) baixados do Yahoo Finance. Cada linha representa uma data e um ticker, com a coluna price_adjusted contendo o preço de fechamento ajustado.

- dados_selic: Dataframe contendo a série temporal da taxa Selic anual e sua conversão para taxa livre de risco diária (Risk_Free_Diario), obtida do Banco Central do Brasil.

- retornos_diarios: Dataframe contendo os retornos diários logarítmicos de cada ativo, calculados a partir de dados_precos. Cada linha representa uma data e um ticker, com a coluna retorno_diario contendo o retorno calculado. Esta é a base para os cálculos de risco e retorno.

- dados_mestre: Dataframe resultante do join entre retornos_diarios e dados_selic, contendo os retornos diários de cada ativo junto com a taxa livre de risco correspondente para cada data.

- features_cluster: Dataframe agregado onde cada linha corresponde a um único ativo (ação), contendo as métricas de desempenho e risco calculadas (RetornoAnual, VolAnual, Sharpe) e a classificação de setor. Este é o dataframe base para a clusterização, sem a atribuição de clusters ainda.

- features_com_cluster: Dataframe features_cluster com a adição da coluna Cluster, contendo a atribuição inicial de clusters (k=3) pelo algoritmo K-Means. Este é o dataframe estático usado para inicialização do dashboard.

- dados_reativos(): Função reativa (Shiny) que recalcula os clusters dinamicamente baseado no valor de k selecionado pelo usuário através do slider "Número de Clusters (k)". Retorna um dataframe similar a features_com_cluster, mas com clusters recalculados conforme o k escolhido pelo usuário (pode variar de 2 a 10).

Principais Variáveis (Colunas)

- ticker: O código de negociação do ativo na bolsa de valores brasileira (B3). Ex: "VALE3.SA".

- Setor: A classificação setorial do ativo, conforme definido pela B3. Ex: "Mineração".

- RetornoAnual: O retorno médio anualizado do ativo. Foi calculado a partir da média dos retornos diários logarítmicos, multiplicada por 252 (número aproximado de dias de pregão em um ano).

- VolAnual: A volatilidade (risco) anualizada do ativo. Medida pelo desvio padrão dos retornos diários, multiplicada pela raiz quadrada de 252. Representa o grau de variação do retorno de um ativo.

- Sharpe: O Índice de Sharpe do ativo. É uma métrica que mede o retorno ajustado ao risco, calculada como:
(RetornoAnual - TaxaLivreDeRiscoMédiaAnual) / VolAnual.
Um valor mais alto indica um melhor desempenho para a quantidade de risco assumido.

- Cluster: O grupo numérico ao qual o ativo foi atribuído pelo algoritmo de aprendizado não supervisionado K-Means, com base em suas características de RetornoAnual, VolAnual e Sharpe (normalizadas). O número de clusters pode variar de 2 a 10, sendo determinado dinamicamente pelo usuário através do slider "Número de Clusters (k)" no dashboard. Cada cluster agrupa ativos com perfis de risco-retorno similares.


### Uso de Inteligência Artificial:
Foi utilizada a ferramenta de IA Gemini para auxiliar na revisão e adequação deste projeto aos critérios da disciplina. O prompt principal utilizado foi:

"Faça uma revisão do projeto Rmd em anexo conforme critérios de avaliação do trabalho na foto em anexo e orientações apresentados a seguir, detalhando o que e como deve ser alterado para se adequar ao escopo do que foi solicitado."

Além disso, foi feito uso da mesma ferramenta para debug e busca por soluções inteligêntes a problemas pontuais ao longo da construção do código do trabalho. Exemplo de feature recomendada pela IA: uso do pacote pacman para carregamento dos demais pacotes.
